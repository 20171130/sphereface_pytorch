{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os \n",
    "os.chdir(\"C:/Users/Henry_B/work/sphere\")\n",
    "os.getcwd()\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "torch.backends.cudnn.bencmark = True\n",
    "\n",
    "import os,sys,cv2,random,datetime\n",
    "import numpy as np\n",
    "\n",
    "from matlab_cp2tform import get_similarity_transform_for_cv2\n",
    "import net_sphere\n",
    "import zipfile\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def alignment(src_img,src_pts):\n",
    "    ref_pts = [ [30.2946, 51.6963],[65.5318, 51.5014],\n",
    "        [48.0252, 71.7366],[33.5493, 92.3655],[62.7299, 92.2041] ]\n",
    "    crop_size = (96, 112)\n",
    "    src_pts = np.array(src_pts).reshape(5,2)\n",
    "\n",
    "    s = np.array(src_pts).astype(np.float32)\n",
    "    r = np.array(ref_pts).astype(np.float32)\n",
    "\n",
    "    tfm = get_similarity_transform_for_cv2(s, r)\n",
    "    face_img = cv2.warpAffine(src_img, tfm, crop_size)\n",
    "    return face_img\n",
    "\n",
    "net = net_sphere.sphere20a()\n",
    "net.load_state_dict(torch.load('model/sphere20a_20171020.pth'))\n",
    "net.cuda()\n",
    "net.eval()\n",
    "net.feature = True # bypasses the laast FC to output features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The result of bicubic interpolotion."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "mean      0.758129\n",
    "std       0.080957\n",
    "after averaging flipped \n",
    "mean      0.771156\n",
    "std       0.077258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "                 0\n",
      "count  6500.000000\n",
      "mean      0.771156\n",
      "std       0.077258\n",
      "min       0.218228\n",
      "25%       0.727591\n",
      "50%       0.780157\n",
      "75%       0.825200\n",
      "max       0.953715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zfile = zipfile.ZipFile(\"data/lfw.zip\")\n",
    "\n",
    "landmark = {}\n",
    "with open('data/lfw_landmark.txt') as f:\n",
    "    landmark_lines = f.readlines()\n",
    "for line in landmark_lines:\n",
    "    l = line.replace('\\n','').split('\\t')\n",
    "    landmark[l[0]] = [int(k) for k in l[1:]]\n",
    "\n",
    "with open('data/pairs.txt') as f:\n",
    "    pairs_lines = f.readlines()[1:]\n",
    "\n",
    "cosdistance = []\n",
    "samples = 6000\n",
    "for _,_,files in os.walk(\"data/lfw\"):\n",
    "    for imgname in files:\n",
    "        person = re.match(\"[^0-9]*\", imgname)\n",
    "        person = person.group(0)\n",
    "        person = person[0:-1]\n",
    "        imgname =person+\"/\"+imgname\n",
    "        img = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgname),np.uint8),1),landmark[imgname])\n",
    "       \n",
    "        \n",
    "        img1 = cv2.resize(img, (24,28),fx=0,fy=0, interpolation =cv2.INTER_CUBIC )\n",
    "        img1 = cv2.resize(img1, (96,112),fx=0,fy=0, interpolation =cv2.INTER_CUBIC )\n",
    "        \n",
    "        \"\"\"\n",
    "        cv2.imshow(imgname, img)\n",
    "        cv2.imshow(\"bicubic\", img1)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \"\"\"\n",
    "        imglist = [img, cv2.flip(img, 1), img1, cv2.flip(img1, 1)]\n",
    "        for i in range(len(imglist)):\n",
    "            imglist[i] = imglist[i].transpose(2, 0, 1).reshape((1,3,112,96))\n",
    "            imglist[i] = (imglist[i]-127.5)/128.0\n",
    "        \n",
    "        img = np.vstack(imglist)\n",
    "        with torch.no_grad():\n",
    "            img = Variable(torch.from_numpy(img).float()).cuda()\n",
    "        output = net(img)\n",
    "        f = output.data\n",
    "        f0, f1 = f[0]+f[1],f[2]+f[3]\n",
    "        tmp = f0.dot(f1)/(f0.norm()*f1.norm()+1e-5)\n",
    "        cosdistance.append(tmp.item())\n",
    "        if(len(cosdistance)%500 == 0):\n",
    "            print(len(cosdistance))\n",
    "            if(len(cosdistance)>samples):\n",
    "                break\n",
    "df = pd.DataFrame(np.array(cosdistance))\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "#img is np.array of shape (batch,3,112,96)\n",
    "#lfw is of 250 250, lfw_eval alignment() resizes\n",
    "# using     matlab_cp2tform.get_similarity_transform_for_cv2(s, r)\n",
    "#    and cv2.warpAffine(src_img, tfm, crop_size)\n",
    "# the self.fc5 (the first FC) requires the resolution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The result of flipping "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean      0.943565\n",
    "std       0.025556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "                 0\n",
      "count  6500.000000\n",
      "mean      0.026688\n",
      "std       0.107153\n",
      "min      -0.436076\n",
      "25%      -0.045648\n",
      "50%       0.026181\n",
      "75%       0.097964\n",
      "max       0.447635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zfile = zipfile.ZipFile(\"data/lfw.zip\")\n",
    "\n",
    "landmark = {}\n",
    "with open('data/lfw_landmark.txt') as f:\n",
    "    landmark_lines = f.readlines()\n",
    "for line in landmark_lines:\n",
    "    l = line.replace('\\n','').split('\\t')\n",
    "    landmark[l[0]] = [int(k) for k in l[1:]]\n",
    "\n",
    "with open('data/pairs.txt') as f:\n",
    "    pairs_lines = f.readlines()[1:]\n",
    "\n",
    "cosdistance = []\n",
    "samples = 6000\n",
    "for _,_,files in os.walk(\"data/lfw\"):\n",
    "    for imgname in files:\n",
    "        person = re.match(\"[^0-9]*\", imgname)\n",
    "        person = person.group(0)\n",
    "        person = person[0:-1]\n",
    "        imgname =person+\"/\"+imgname\n",
    "        img = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgname),np.uint8),1),landmark[imgname])\n",
    "       \n",
    "        img1 = cv2.flip(img, 0)\n",
    "        imglist = [img, img1]\n",
    "        for i in range(len(imglist)):\n",
    "            imglist[i] = imglist[i].transpose(2, 0, 1).reshape((1,3,112,96))\n",
    "            imglist[i] = (imglist[i]-127.5)/128.0\n",
    "        \n",
    "        img = np.vstack(imglist)\n",
    "        with torch.no_grad():\n",
    "            img = Variable(torch.from_numpy(img).float()).cuda()\n",
    "        output = net(img)\n",
    "        f = output.data\n",
    "        f0, f1 = f[0],f[1]\n",
    "        tmp = f0.dot(f1)/(f0.norm()*f1.norm()+1e-5)\n",
    "        cosdistance.append(tmp.item())\n",
    "        if(len(cosdistance)%500 == 0):\n",
    "            print(len(cosdistance))\n",
    "            if(len(cosdistance)>samples):\n",
    "                break\n",
    "df = pd.DataFrame(np.array(cosdistance))\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "#img is np.array of shape (batch,3,112,96)\n",
    "#lfw is of 250 250, lfw_eval alignment() resizes\n",
    "# using     matlab_cp2tform.get_similarity_transform_for_cv2(s, r)\n",
    "#    and cv2.warpAffine(src_img, tfm, crop_size)\n",
    "# the self.fc5 (the first FC) requires the resolution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The result of different instances of one person"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "mean      0.641985\n",
    "std       0.128602\n",
    "after averaging flipped:\n",
    "mean      0.658332\n",
    "std       0.127805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "                 0\n",
      "count  1680.000000\n",
      "mean      0.658332\n",
      "std       0.127805\n",
      "min      -0.033425\n",
      "25%       0.583516\n",
      "50%       0.669929\n",
      "75%       0.746939\n",
      "max       0.967443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zfile = zipfile.ZipFile(\"data/lfw.zip\")\n",
    "\n",
    "landmark = {}\n",
    "with open('data/lfw_landmark.txt') as f:\n",
    "    landmark_lines = f.readlines()\n",
    "for line in landmark_lines:\n",
    "    l = line.replace('\\n','').split('\\t')\n",
    "    landmark[l[0]] = [int(k) for k in l[1:]]\n",
    "\n",
    "with open('data/pairs.txt') as f:\n",
    "    pairs_lines = f.readlines()[1:]\n",
    "\n",
    "cosdistance = []\n",
    "samples = 6000\n",
    "for _,_,files in os.walk(\"data/lfw\"):\n",
    "    for imgname in files:\n",
    "        person = re.match(\"[^0-9]*\", imgname)\n",
    "        person = person.group(0)\n",
    "        person = person[0:-1]\n",
    "        imgname =person+\"/\"+imgname\n",
    "        \n",
    "        imgnum = re.search(r\"\\d+\", imgname).group(0)\n",
    "        if imgnum == \"0002\":\n",
    "            imgname1 = re.sub(\"0002\", \"0001\" ,imgname)\n",
    "          \n",
    "            img = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgname),np.uint8),1),landmark[imgname])\n",
    "            img1 = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgname1),np.uint8),1),landmark[imgname1])\n",
    "\n",
    "            \"\"\"\n",
    "            cv2.imshow(imgname, img)         \n",
    "            cv2.imshow(imgname1, img1)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \"\"\"\n",
    "            \n",
    "            imglist = [img, cv2.flip(img, 1), img1, cv2.flip(img1, 1)]\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = imglist[i].transpose(2, 0, 1).reshape((1,3,112,96))\n",
    "                imglist[i] = (imglist[i]-127.5)/128.0\n",
    "\n",
    "            img = np.vstack(imglist)\n",
    "            with torch.no_grad():\n",
    "                img = Variable(torch.from_numpy(img).float()).cuda()\n",
    "            output = net(img)\n",
    "            f = output.data\n",
    "            f0, f1 = f[0]+f[1],f[2]+f[3]\n",
    "            tmp = f0.dot(f1)/(f0.norm()*f1.norm()+1e-5)\n",
    "            cosdistance.append(tmp.item())\n",
    "            if(len(cosdistance)%500 == 0):\n",
    "                print(len(cosdistance))\n",
    "                if(len(cosdistance)>samples):\n",
    "                    break\n",
    "df = pd.DataFrame(np.array(cosdistance))\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random image pairs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean      0.038778\n",
    "std       0.124721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "                 0\n",
      "count  6500.000000\n",
      "mean      0.038778\n",
      "std       0.124721\n",
      "min      -0.367741\n",
      "25%      -0.043736\n",
      "50%       0.033764\n",
      "75%       0.115174\n",
      "max       0.834991\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zfile = zipfile.ZipFile(\"data/lfw.zip\")\n",
    "\n",
    "landmark = {}\n",
    "with open('data/lfw_landmark.txt') as f:\n",
    "    landmark_lines = f.readlines()\n",
    "for line in landmark_lines:\n",
    "    l = line.replace('\\n','').split('\\t')\n",
    "    landmark[l[0]] = [int(k) for k in l[1:]]\n",
    "\n",
    "with open('data/pairs.txt') as f:\n",
    "    pairs_lines = f.readlines()[1:]\n",
    "\n",
    "cosdistance = []\n",
    "samples = 6000\n",
    "imgnames = []\n",
    "for _,_,files in os.walk(\"data/lfw\"):\n",
    "    for imgname in files:\n",
    "        person = re.match(\"[^0-9]*\", imgname)\n",
    "        person = person.group(0)\n",
    "        person = person[0:-1]\n",
    "        imgname =person+\"/\"+imgname\n",
    "        imgnames.append(imgname)\n",
    "        \n",
    "for imgname in imgnames:    \n",
    "        img = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgname),np.uint8),1),landmark[imgname])\n",
    "       \n",
    "        tmp = np.random.randint(len(imgnames))\n",
    "        img1 = alignment(cv2.imdecode(np.frombuffer(zfile.read(imgnames[tmp]),np.uint8),1),landmark[imgnames[tmp]])\n",
    "        imglist = [img, img1]\n",
    "        for i in range(len(imglist)):\n",
    "            imglist[i] = imglist[i].transpose(2, 0, 1).reshape((1,3,112,96))\n",
    "            imglist[i] = (imglist[i]-127.5)/128.0\n",
    "        \n",
    "        img = np.vstack(imglist)\n",
    "        with torch.no_grad():\n",
    "            img = Variable(torch.from_numpy(img).float()).cuda()\n",
    "        output = net(img)\n",
    "        f = output.data\n",
    "        f0, f1 = f[0],f[1]\n",
    "        tmp = f0.dot(f1)/(f0.norm()*f1.norm()+1e-5)\n",
    "        cosdistance.append(tmp.item())\n",
    "        if(len(cosdistance)%500 == 0):\n",
    "            print(len(cosdistance))\n",
    "            if(len(cosdistance)>samples):\n",
    "                break\n",
    "df = pd.DataFrame(np.array(cosdistance))\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "#img is np.array of shape (batch,3,112,96)\n",
    "#lfw is of 250 250, lfw_eval alignment() resizes\n",
    "# using     matlab_cp2tform.get_similarity_transform_for_cv2(s, r)\n",
    "#    and cv2.warpAffine(src_img, tfm, crop_size)\n",
    "# the self.fc5 (the first FC) requires the resolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
